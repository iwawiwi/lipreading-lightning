{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/iwawiwi/research/22/lipreading-lightning/\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model and data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lrw_module import LRWLitModule\n",
    "from src.datamodules.components.lrw_dataset import LRWDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_MODEL = \"lrw_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model using lightning module\n",
    "big_model = LRWLitModule.load_from_checkpoint(BIG_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = big_model.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate net performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/iwawiwi/research/22/lipreading-lightning/data/lrw_cropped\"\n",
    "test_set = LRWDataset(DATA_PATH, phase=\"test\")\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False, num_workers=0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device) # use GPU if available\n",
    "\n",
    "# test and compute accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[\"video\"].to(device), data[\"label\"].long().to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"Accuracy of the network on the test images: %.2f %%\" % (100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy: $84.52\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pytorch pruning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all module' names from the network\n",
    "for name, module in net.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sequential module (instance of ```torch.nn.Sequential```), number valued entry indicated array index position of the module in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do global pruning on ```net```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "t = 1e-6\n",
    "\n",
    "# calculate sparsity in model based on threshold\n",
    "sparsity = 0\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        sparsity += float(param.numel() - param.nonzero().shape[0]) / param.numel()\n",
    "\n",
    "        if param.numel() > 0:\n",
    "            param.data = torch.where(param.data > t, param.data, torch.zeros_like(param.data))\n",
    "\n",
    "        print(name, param.numel(), param.nonzero().shape[0], \"\\n\", float(param.numel() - param.nonzero().shape[0]) / param.numel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of sequential module can be accesed using array\n",
    "parameters_to_prune = (\n",
    "    #(net.video_cnn.frontend3D[0], 'weight'), \n",
    "    #(net.video_cnn.resnet18.layer1[0].conv1, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer1[0].conv2, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer1[1].conv1, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer1[1].conv2, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer2[0].conv1, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer2[0].conv2, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer2[1].conv1, \"weight\"),\n",
    "    #(net.video_cnn.resnet18.layer2[1].conv2, \"weight\"),\n",
    "    (net.v_cls, \"weight\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0, # 0% smallest weight (defined globally from ```parameters_to_prune```) will be pruned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check buffer\n",
    "print(list(net.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check forward pre-hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(net.named_buffers()).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove re-parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module, param in parameters_to_prune:\n",
    "    prune.remove(module, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model aftar pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device) # use GPU if available\n",
    "\n",
    "# test and compute accuracy\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[\"video\"].to(device), data[\"label\"].long().to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"Accuracy of the network on the test images: %.2f %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy after pruning: $0.20\\%$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torchlight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2dd0912a7cefb2d506aeeb16f751d49908d61cb2cdcc882d6a1ed2ecca85104b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
