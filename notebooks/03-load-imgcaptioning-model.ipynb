{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory to PATH system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/iwawiwi/research/22/lipreading-lightning\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from src.models.imgcaption_module import Flickr8KLitModule\n",
    "from src.datamodules.components.flickr8k import Flickr8kDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/iwawiwi/research/22/lipreading-lightning/logs/experiments/runs/imgcaption_net/2022-06-09_14-41-18/checkpoints/last.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Flickr8KLitModule.load_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "# print loaded model hparams\n",
    "print(trained_model.hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Flickr8kDataset(\n",
    "    root_dir=\"/home/iwawiwi/research/22/lipreading-lightning/data/flickr8k/Images\", \n",
    "    captions_file=\"/home/iwawiwi/research/22/lipreading-lightning/data/flickr8k/captions.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.hparams.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img path\n",
    "img_path = \"/home/iwawiwi/research/22/lipreading-lightning/src/vendor/example/dog.jpg\"\n",
    "\n",
    "# image transform routine\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# test image\n",
    "test_img1 = transform(Image.open(img_path).convert(\"RGB\")).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print expected caption and predicted caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 1 CORRECT: Dog on a beach by the ocean\")\n",
    "\n",
    "# model prediction\n",
    "output = trained_model.net.caption_image(test_img1, dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 1 OUTPUT: \" + \" \".join(output))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd0912a7cefb2d506aeeb16f751d49908d61cb2cdcc882d6a1ed2ecca85104b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torchlight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
